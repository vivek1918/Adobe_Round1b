# ğŸ§  Intelligent Document Analyst

An AI-powered system that extracts and prioritizes relevant content from multi-format PDF documents based on user persona and their job-to-be-done. Optimized for performance under strict hardware and time constraints.

---

## ğŸ” Overview

This system processes and analyzes documents to extract semantically relevant sections, adapting outputs for different user personas like researchers, analysts, and students. It leverages a hybrid NLP pipeline combining structure, semantics, and formatting analysis for high-precision results.

---

## âš™ï¸ Key Components

### 1. ğŸ“„ Document Processing
- **Parallel PDF Extraction**: Uses PyMuPDF + thread pooling for fast multi-page extraction.
- **Structure Analysis**: Detects headers, section breaks, and formatting using font metadata.
- **Content Chunking**: Segments documents into logical units for deeper analysis.

### 2. ğŸ§  Content Analysis
- **Semantic Understanding**: Uses Sentence-BERT (`all-MiniLM-L6-v2`) for lightweight yet powerful embeddings.
- **Keyword Extraction**: Combines spaCy NLP pipeline with domain-aware heuristics.
- **Entity Recognition**: Identifies key entities (people, orgs, locations) to gauge importance.
- **Formatting Analysis**: Boosts prominence score using font size, boldness, and other visual cues.

### 3. ğŸ“Š Relevance Ranking
- **Multi-Feature Scoring**: Blends semantic similarity, keyword overlap, and formatting weight.
- **Persona-Adaptive Weights**: Adjusts ranking logic based on the persona type.
- **Diversity Preservation**: Ensures extracted content represents multiple sections/documents.

### 4. ğŸš€ Performance Optimization
- **Lightweight Models**: All NLP components are optimized to stay under 1GB RAM usage.
- **Thread Parallelism**: Efficient CPU usage via concurrent processing.
- **Memory-Efficient Structures**: Optimized data flow to reduce system load.

---

## ğŸ’¡ Technical Highlights

- **Hybrid Relevance Scoring**  
  Combines BERT-based semantic similarity with traditional keyword matching for best-in-class precision.

- **Persona-Aware Adaptation**  
  Dynamically adjusts relevance weights and keyword focus based on roles like:
  - Researcher
  - Business Analyst
  - Student

- **Hard Constraint Compliance**
  - CPU-only processing
  - <1GB memory usage
  - <60 seconds processing time

---

## âœ… Evaluation Results

| Persona Type       | Test Case                  | Outcome                                    |
|--------------------|----------------------------|--------------------------------------------|
| Academic Research  | Research paper PDFs        | Correctly identified methodology sections  |
| Business Analyst   | Financial reports          | Extracted KPIs and trend highlights        |
| Student            | Exam content PDFs          | Highlighted key concepts and summaries     |

---

## ğŸ³ Docker Usage

### ğŸ”§ Build the Image
```bash
docker build -t round1b .
```
## ğŸš€Run the Container
``` bash
docker run -v "C:\Users\Vivek Vasani\intelligent_document_analyst1\intelligent_document_analyst\input:/app/input" -v "C:\Users\Vivek Vasani\intelligent_document_analyst1\intelligent_document_analyst\output:/app/output" round1b
```

## Repository Structure
``` bash
intelligent_document_analyst/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/                # ML models and embeddings
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analyzer.py            # Content analysis logic
â”‚   â”œâ”€â”€ document_processor/    # PDF processing components
â”‚   â”œâ”€â”€ main.py               # Entry point
â”‚   â”œâ”€â”€ ranking.py            # Relevance ranking logic
â”‚   â”œâ”€â”€ utils.py              # Helper functions
â”œâ”€â”€ input/
â”‚   â”œâ”€â”€ job.json              # Job description input
â”‚   â”œâ”€â”€ personal.json         # Persona characteristics
â”‚   â”œâ”€â”€ documents.json        # Input documents to analyze
â”œâ”€â”€ output/                   # Generated analysis results
â”œâ”€â”€ tests/                    # Test cases
â”œâ”€â”€ venv/
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ run.sh                    # Convenience run script
```